device: 'cuda'
data_path: 'data/format/ifeval_augmented_filtered.jsonl'
dry_run: False
transformers_cache_dir: null

model_name: '/home/uom/.cache/huggingface/hub/models--Qwen--Qwen3-1.7B/snapshots/0060bc56d46589041c1048efd1a397421b1142b5'
max_generation_length: 2 # increase to check model's outputs, decrease for faster computation
num_final_tokens: 1
use_data_subset: False
data_subset_ratio: 0.7

defaults:
  - _self_
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

hydra:
  output_subdir: null
  run:
    dir: .